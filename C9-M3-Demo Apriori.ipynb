{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF29mUbRLh9E"
   },
   "source": [
    "## Create a Dummy Dataset of 1,000 Transactions in a Grocery Store\n",
    "For this tutorial, we'll create a dummy dataset representing 1,000 transactions in a grocery store. Each transaction will contain a random selection of items from a list of 10 unique items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1690677862944,
     "user": {
      "displayName": "Di Wu",
      "userId": "05255951341257561169"
     },
     "user_tz": 240
    },
    "id": "D8ZSaILxLk7W",
    "outputId": "03be3f69-38c6-4872-c34c-60bcff9456f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Item1  Item10  Item2  Item3  Item4  Item5  Item6  Item7  Item8  Item9\n",
      "0     True    True   True   True  False  False   True   True  False   True\n",
      "1     True    True   True   True  False  False   True   True   True   True\n",
      "2    False   False  False   True  False  False  False   True  False  False\n",
      "3     True    True   True   True   True   True   True   True   True   True\n",
      "4     True    True   True   True   True   True   True  False   True   True\n",
      "..     ...     ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
      "995   True   False   True   True  False  False  False  False  False   True\n",
      "996  False   False  False  False  False  False  False   True  False  False\n",
      "997   True   False  False   True   True   True  False   True  False   True\n",
      "998  False    True  False   True  False  False  False   True  False  False\n",
      "999  False   False  False  False   True  False  False   True   True   True\n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of records (transactions) in the dataset\n",
    "num_records = 1000\n",
    "\n",
    "# Number of unique items in the grocery store\n",
    "num_items = 10\n",
    "\n",
    "# Generate the dummy dataset\n",
    "transactions = []\n",
    "for _ in range(num_records):\n",
    "    num_items_in_transaction = np.random.randint(1, num_items + 1)\n",
    "    items = np.random.choice(range(1, num_items + 1), num_items_in_transaction, replace=False)\n",
    "    transactions.append([f\"Item{item}\" for item in items])\n",
    "\n",
    "# Convert the dataset into a one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGnBqQvbNWFe"
   },
   "source": [
    "## Perform Frequent Itemset Mining using Apriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1690678018877,
     "user": {
      "displayName": "Di Wu",
      "userId": "05255951341257561169"
     },
     "user_tz": 240
    },
    "id": "A12CtHVJNYKP",
    "outputId": "2556be64-c023-4164-a9f2-8a9495813a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support         itemsets\n",
      "0     0.530          (Item1)\n",
      "1     0.546         (Item10)\n",
      "2     0.543          (Item2)\n",
      "3     0.545          (Item3)\n",
      "4     0.527          (Item4)\n",
      "5     0.540          (Item5)\n",
      "6     0.533          (Item6)\n",
      "7     0.532          (Item7)\n",
      "8     0.533          (Item8)\n",
      "9     0.545          (Item9)\n",
      "10    0.358   (Item1, Item5)\n",
      "11    0.358  (Item2, Item10)\n",
      "12    0.359  (Item3, Item10)\n",
      "13    0.351  (Item4, Item10)\n",
      "14    0.353  (Item5, Item10)\n",
      "15    0.364  (Item9, Item10)\n",
      "16    0.351   (Item4, Item2)\n",
      "17    0.357   (Item6, Item2)\n",
      "18    0.352   (Item2, Item8)\n",
      "19    0.362   (Item9, Item2)\n",
      "20    0.354   (Item4, Item3)\n",
      "21    0.362   (Item5, Item3)\n",
      "22    0.357   (Item6, Item3)\n",
      "23    0.360   (Item3, Item7)\n",
      "24    0.362   (Item3, Item8)\n",
      "25    0.356   (Item9, Item3)\n",
      "26    0.358   (Item4, Item5)\n",
      "27    0.350   (Item4, Item8)\n",
      "28    0.352   (Item4, Item9)\n",
      "29    0.352   (Item6, Item5)\n",
      "30    0.352   (Item5, Item8)\n",
      "31    0.356   (Item9, Item5)\n",
      "32    0.354   (Item6, Item8)\n",
      "33    0.355   (Item9, Item8)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Define the minimum support threshold (e.g., 0.05 means an itemset must appear in at least 5% of transactions)\n",
    "min_support = 0.35\n",
    "\n",
    "# Perform frequent itemset mining using Apriori\n",
    "frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnIJEZsyNf0E"
   },
   "source": [
    "## Generate Association Rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1690678059783,
     "user": {
      "displayName": "Di Wu",
      "userId": "05255951341257561169"
     },
     "user_tz": 240
    },
    "id": "NoJs6mS_NhVP",
    "outputId": "f735d4d6-a17f-4707-a46d-2410e2d5aa4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0     (Item1)     (Item5)               0.530               0.540    0.358   \n",
      "1     (Item4)     (Item3)               0.527               0.545    0.354   \n",
      "2     (Item5)     (Item3)               0.540               0.545    0.362   \n",
      "3     (Item7)     (Item3)               0.532               0.545    0.360   \n",
      "4     (Item8)     (Item3)               0.533               0.545    0.362   \n",
      "5     (Item4)     (Item5)               0.527               0.540    0.358   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0    0.675472  1.250874  0.071800    1.417442       0.426721  \n",
      "1    0.671727  1.232526  0.066785    1.386040       0.398855  \n",
      "2    0.670370  1.230037  0.067700    1.380337       0.406558  \n",
      "3    0.676692  1.241636  0.070060    1.407326       0.415836  \n",
      "4    0.679174  1.246192  0.071515    1.418216       0.423031  \n",
      "5    0.679317  1.257994  0.073420    1.434438       0.433581  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Generate association rules with minimum confidence threshold (e.g., 0.5)\n",
    "min_confidence = 0.67\n",
    "association_rules_df = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(association_rules_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of the results : \n",
    "\n",
    "All the rules have confidence values between approximately 0.67 and 0.68, indicating a moderate likelihood that the consequent occurs when the antecedent is present.\n",
    "\n",
    "The lift values range from 1.23 to 1.26, indicating a positive association between the antecedents and consequents.(A lift greater than 1 suggests that the antecedent increases the likelihood of the consequent occurring.)\n",
    "\n",
    "The support values for these rules are between 0.354 and 0.362 (meaning these itemsets occur together in about 35-36% of all transactions). \n",
    "\n",
    "Zhangâ€™s metric values are around 0.40 to 0.43, indicating a moderate strength of association.\n",
    "\n",
    "Conviction values range from 1.38 to 1.43, suggesting that the rules have some predictive power, with the occurrence of the antecedent somewhat increasing the likelihood of the consequent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGC8/B6F3mZwG/FEo5QoH8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
